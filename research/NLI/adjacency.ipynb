{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "adjacency.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jGuJWHhCJ8L",
        "outputId": "dcd10116-562b-4e50-ebc6-631d2aef70d7"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import re\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMwTFPfVZ6G1",
        "outputId": "1caa9462-1c84-4679-d275-fc2a60197863"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWnHB024C6oS"
      },
      "source": [
        "class InferSent(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(InferSent, self).__init__()\n",
        "        self.bsize = config['bsize']\n",
        "        self.word_emb_dim = config['word_emb_dim']\n",
        "        self.enc_lstm_dim = config['enc_lstm_dim']\n",
        "        self.pool_type = config['pool_type']\n",
        "        self.dpout_model = config['dpout_model']\n",
        "        self.version = 1 if 'version' not in config else config['version']\n",
        "\n",
        "        self.enc_lstm = nn.LSTM(self.word_emb_dim, self.enc_lstm_dim, 1,\n",
        "                                bidirectional=True, dropout=self.dpout_model)\n",
        "\n",
        "        assert self.version in [1, 2]\n",
        "        if self.version == 1:\n",
        "            self.bos = '<s>'\n",
        "            self.eos = '</s>'\n",
        "            self.max_pad = True\n",
        "            self.moses_tok = False\n",
        "        elif self.version == 2:\n",
        "            self.bos = '<p>'\n",
        "            self.eos = '</p>'\n",
        "            self.max_pad = False\n",
        "            self.moses_tok = True\n",
        "\n",
        "    def is_cuda(self):\n",
        "        # either all weights are on cpu or they are on gpu\n",
        "        return self.enc_lstm.bias_hh_l0.data.is_cuda\n",
        "\n",
        "    def forward(self, sent_tuple):\n",
        "        # sent_len: [max_len, ..., min_len] (bsize)\n",
        "        # sent: (seqlen x bsize x worddim)\n",
        "        sent, sent_len = sent_tuple\n",
        "\n",
        "        # Sort by length (keep idx)\n",
        "        sent_len_sorted, idx_sort = np.sort(sent_len)[::-1], np.argsort(-sent_len)\n",
        "        sent_len_sorted = sent_len_sorted.copy()\n",
        "        idx_unsort = np.argsort(idx_sort)\n",
        "\n",
        "        idx_sort = torch.from_numpy(idx_sort).cuda() if self.is_cuda() \\\n",
        "            else torch.from_numpy(idx_sort)\n",
        "        sent = sent.index_select(1, idx_sort)\n",
        "\n",
        "        # Handling padding in Recurrent Networks\n",
        "        sent_packed = nn.utils.rnn.pack_padded_sequence(sent, sent_len_sorted)\n",
        "        sent_output = self.enc_lstm(sent_packed)[0]  # seqlen x batch x 2*nhid\n",
        "        sent_output = nn.utils.rnn.pad_packed_sequence(sent_output)[0]\n",
        "\n",
        "        # Un-sort by length\n",
        "        idx_unsort = torch.from_numpy(idx_unsort).cuda() if self.is_cuda() \\\n",
        "            else torch.from_numpy(idx_unsort)\n",
        "        sent_output = sent_output.index_select(1, idx_unsort)\n",
        "\n",
        "        # Pooling\n",
        "        if self.pool_type == \"mean\":\n",
        "            sent_len = torch.FloatTensor(sent_len.copy()).unsqueeze(1).cuda()\n",
        "            emb = torch.sum(sent_output, 0).squeeze(0)\n",
        "            emb = emb / sent_len.expand_as(emb)\n",
        "        elif self.pool_type == \"max\":\n",
        "            if not self.max_pad:\n",
        "                sent_output[sent_output == 0] = -1e9\n",
        "            emb = torch.max(sent_output, 0)[0]\n",
        "            if emb.ndimension() == 3:\n",
        "                emb = emb.squeeze(0)\n",
        "                assert emb.ndimension() == 2\n",
        "\n",
        "        return emb\n",
        "\n",
        "    def set_w2v_path(self, w2v_path):\n",
        "        self.w2v_path = w2v_path\n",
        "\n",
        "    def get_word_dict(self, sentences, tokenize=True):\n",
        "        # create vocab of words\n",
        "        word_dict = {}\n",
        "        sentences = [s.split() if not tokenize else self.tokenize(s) for s in sentences]\n",
        "        for sent in sentences:\n",
        "            for word in sent:\n",
        "                if word not in word_dict:\n",
        "                    word_dict[word] = ''\n",
        "        word_dict[self.bos] = ''\n",
        "        word_dict[self.eos] = ''\n",
        "        return word_dict\n",
        "\n",
        "    def get_w2v(self, word_dict):\n",
        "        assert hasattr(self, 'w2v_path'), 'w2v path not set'\n",
        "        # create word_vec with w2v vectors\n",
        "        word_vec = {}\n",
        "        with open(self.w2v_path, encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                word, vec = line.split(' ', 1)\n",
        "                if word in word_dict:\n",
        "                    word_vec[word] = np.fromstring(vec, sep=' ')\n",
        "        print('Found %s(/%s) words with w2v vectors' % (len(word_vec), len(word_dict)))\n",
        "        return word_vec\n",
        "\n",
        "    def get_w2v_k(self, K):\n",
        "        assert hasattr(self, 'w2v_path'), 'w2v path not set'\n",
        "        # create word_vec with k first w2v vectors\n",
        "        k = 0\n",
        "        word_vec = {}\n",
        "        with open(self.w2v_path, encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                word, vec = line.split(' ', 1)\n",
        "                if k <= K:\n",
        "                    word_vec[word] = np.fromstring(vec, sep=' ')\n",
        "                    k += 1\n",
        "                if k > K:\n",
        "                    if word in [self.bos, self.eos]:\n",
        "                        word_vec[word] = np.fromstring(vec, sep=' ')\n",
        "\n",
        "                if k > K and all([w in word_vec for w in [self.bos, self.eos]]):\n",
        "                    break\n",
        "        return word_vec\n",
        "\n",
        "    def build_vocab(self, sentences, tokenize=True):\n",
        "        assert hasattr(self, 'w2v_path'), 'w2v path not set'\n",
        "        word_dict = self.get_word_dict(sentences, tokenize)\n",
        "        self.word_vec = self.get_w2v(word_dict)\n",
        "        print('Vocab size : %s' % (len(self.word_vec)))\n",
        "\n",
        "    # build w2v vocab with k most frequent words\n",
        "    def build_vocab_k_words(self, K):\n",
        "        assert hasattr(self, 'w2v_path'), 'w2v path not set'\n",
        "        self.word_vec = self.get_w2v_k(K)\n",
        "        print('Vocab size : %s' % (K))\n",
        "\n",
        "    def update_vocab(self, sentences, tokenize=True):\n",
        "        assert hasattr(self, 'w2v_path'), 'warning : w2v path not set'\n",
        "        assert hasattr(self, 'word_vec'), 'build_vocab before updating it'\n",
        "        word_dict = self.get_word_dict(sentences, tokenize)\n",
        "\n",
        "        # keep only new words\n",
        "        for word in self.word_vec:\n",
        "            if word in word_dict:\n",
        "                del word_dict[word]\n",
        "\n",
        "        # udpate vocabulary\n",
        "        if word_dict:\n",
        "            new_word_vec = self.get_w2v(word_dict)\n",
        "            self.word_vec.update(new_word_vec)\n",
        "        else:\n",
        "            new_word_vec = []\n",
        "        print('New vocab size : %s (added %s words)'% (len(self.word_vec), len(new_word_vec)))\n",
        "\n",
        "    def get_batch(self, batch):\n",
        "        # sent in batch in decreasing order of lengths\n",
        "        # batch: (bsize, max_len, word_dim)\n",
        "        embed = np.zeros((len(batch[0]), len(batch), self.word_emb_dim))\n",
        "\n",
        "        for i in range(len(batch)):\n",
        "            for j in range(len(batch[i])):\n",
        "                embed[j, i, :] = self.word_vec[batch[i][j]]\n",
        "\n",
        "        return torch.FloatTensor(embed)\n",
        "\n",
        "    def tokenize(self, s):\n",
        "        from nltk.tokenize import word_tokenize\n",
        "        if self.moses_tok:\n",
        "            s = ' '.join(word_tokenize(s))\n",
        "            s = s.replace(\" n't \", \"n 't \")  # HACK to get ~MOSES tokenization\n",
        "            return s.split()\n",
        "        else:\n",
        "            return word_tokenize(s)\n",
        "\n",
        "    def prepare_samples(self, sentences, bsize, tokenize, verbose):\n",
        "        sentences = [[self.bos] + s.split() + [self.eos] if not tokenize else\n",
        "                     [self.bos] + self.tokenize(s) + [self.eos] for s in sentences]\n",
        "        n_w = np.sum([len(x) for x in sentences])\n",
        "\n",
        "        # filters words without w2v vectors\n",
        "        for i in range(len(sentences)):\n",
        "            s_f = [word for word in sentences[i] if word in self.word_vec]\n",
        "            if not s_f:\n",
        "                import warnings\n",
        "                warnings.warn('No words in \"%s\" (idx=%s) have w2v vectors. \\\n",
        "                               Replacing by \"</s>\"..' % (sentences[i], i))\n",
        "                s_f = [self.eos]\n",
        "            sentences[i] = s_f\n",
        "\n",
        "        lengths = np.array([len(s) for s in sentences])\n",
        "        n_wk = np.sum(lengths)\n",
        "        if verbose:\n",
        "            print('Nb words kept : %s/%s (%.1f%s)' % (\n",
        "                        n_wk, n_w, 100.0 * n_wk / n_w, '%'))\n",
        "\n",
        "        # sort by decreasing length\n",
        "        lengths, idx_sort = np.sort(lengths)[::-1], np.argsort(-lengths)\n",
        "        sentences = np.array(sentences)[idx_sort]\n",
        "\n",
        "        return sentences, lengths, idx_sort\n",
        "\n",
        "    def encode(self, sentences, bsize=64, tokenize=True, verbose=False):\n",
        "        tic = time.time()\n",
        "        sentences, lengths, idx_sort = self.prepare_samples(\n",
        "                        sentences, bsize, tokenize, verbose)\n",
        "\n",
        "        embeddings = []\n",
        "        for stidx in range(0, len(sentences), bsize):\n",
        "            batch = self.get_batch(sentences[stidx:stidx + bsize])\n",
        "            if self.is_cuda():\n",
        "                batch = batch.cuda()\n",
        "            with torch.no_grad():\n",
        "                batch = self.forward((batch, lengths[stidx:stidx + bsize])).data.cpu().numpy()\n",
        "            embeddings.append(batch)\n",
        "        embeddings = np.vstack(embeddings)\n",
        "\n",
        "        # unsort\n",
        "        idx_unsort = np.argsort(idx_sort)\n",
        "        embeddings = embeddings[idx_unsort]\n",
        "\n",
        "        if verbose:\n",
        "            print('Speed : %.1f sentences/s (%s mode, bsize=%s)' % (\n",
        "                    len(embeddings)/(time.time()-tic),\n",
        "                    'gpu' if self.is_cuda() else 'cpu', bsize))\n",
        "        return embeddings\n",
        "\n",
        "    def visualize(self, sent, tokenize=True):\n",
        "\n",
        "        sent = sent.split() if not tokenize else self.tokenize(sent)\n",
        "        sent = [[self.bos] + [word for word in sent if word in self.word_vec] + [self.eos]]\n",
        "\n",
        "        if ' '.join(sent[0]) == '%s %s' % (self.bos, self.eos):\n",
        "            import warnings\n",
        "            warnings.warn('No words in \"%s\" have w2v vectors. Replacing \\\n",
        "                           by \"%s %s\"..' % (sent, self.bos, self.eos))\n",
        "        batch = self.get_batch(sent)\n",
        "\n",
        "        if self.is_cuda():\n",
        "            batch = batch.cuda()\n",
        "        output = self.enc_lstm(batch)[0]\n",
        "        output, idxs = torch.max(output, 0)\n",
        "        # output, idxs = output.squeeze(), idxs.squeeze()\n",
        "        idxs = idxs.data.cpu().numpy()\n",
        "        argmaxs = [np.sum((idxs == k)) for k in range(len(sent[0]))]\n",
        "\n",
        "        # visualize model\n",
        "        import matplotlib.pyplot as plt\n",
        "        x = range(len(sent[0]))\n",
        "        y = [100.0 * n / np.sum(argmaxs) for n in argmaxs]\n",
        "        plt.xticks(x, sent[0], rotation=45)\n",
        "        plt.bar(x, y)\n",
        "        plt.ylabel('%')\n",
        "        plt.title('Visualisation of words importance')\n",
        "        plt.show()\n",
        "\n",
        "        return output, idxs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUq5W5A1C8z0",
        "outputId": "13311df7-d759-4dd1-8110-d43598b97d76"
      },
      "source": [
        "!mkdir fastText\n",
        "!curl -Lo fastText/crawl-300d-2M.vec.zip https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\n",
        "!unzip fastText/crawl-300d-2M.vec.zip -d fastText/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1453M  100 1453M    0     0  43.0M      0  0:00:33  0:00:33 --:--:-- 45.2M\n",
            "Archive:  fastText/crawl-300d-2M.vec.zip\n",
            "  inflating: fastText/crawl-300d-2M.vec  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gobG5yFNulB",
        "outputId": "033fabc9-f3bc-4671-d1e9-da8fe169b5ff"
      },
      "source": [
        "!mkdir encoder\n",
        "!curl -Lo encoder/infersent2.pkl https://dl.fbaipublicfiles.com/infersent/infersent2.pkl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  146M  100  146M    0     0  54.2M      0  0:00:02  0:00:02 --:--:-- 54.2M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6r_4BWjDOGU"
      },
      "source": [
        "def build_nli_net():\n",
        "  V = 2\n",
        "  MODEL_PATH = 'encoder/infersent%s.pkl' % V\n",
        "  params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
        "                  'pool_type': 'max', 'dpout_model': 0.0, 'version': V}\n",
        "  infersent = InferSent(params_model)\n",
        "  infersent.load_state_dict(torch.load(MODEL_PATH))\n",
        "  return infersent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al33yHLrDR2Z"
      },
      "source": [
        "infersent = build_nli_net()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuvKcywGDSQi"
      },
      "source": [
        "W2V_PATH = 'fastText/crawl-300d-2M.vec'\n",
        "infersent.set_w2v_path(W2V_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYxkVTNSDUCj",
        "outputId": "2b094ac4-32e4-49a8-a23c-2f1c3747ce9c"
      },
      "source": [
        "infersent.build_vocab_k_words(K=500000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size : 500000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSvvyNxnDquG"
      },
      "source": [
        "def text_prepare(text):\n",
        "    REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;#]')\n",
        "    BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "    # text = str(text)\n",
        "    # text = \" \".join([word for word in text.split(\" \") if re.search('[a-zA-Z]', word)])\n",
        "    # text = text.lower()\n",
        "    # text = re.sub(REPLACE_BY_SPACE_RE, \" \", text)\n",
        "    # text = re.sub(BAD_SYMBOLS_RE, \"\", text)\n",
        "    return text\n",
        "\n",
        "def cosine(u, v):\n",
        "  # compute the similarity between two embeddings\n",
        "  # u and v are matrices!\n",
        "    result = np.einsum('ij,ij->i', u, v) / ((np.linalg.norm(u, axis=1) * np.linalg.norm(v, axis=1)))\n",
        "    return np.log(result) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghxPfXp5DYwa",
        "outputId": "ba8fa4de-ccda-4274-e88e-bbdb6b3f3137"
      },
      "source": [
        "tweet_1 = \"Since the start of the pandemic, a total 65 WHO staff stationed in Geneva - working from home and onsite - have tested positive for #COVID19. We have not yet established whether any transmission has occurred on campus, but are looking into the matter.\"\n",
        "tweet_2 = \"WHO staff who were confirmed positive with #COVID19 in Geneva have received the necessary medical attention. WHO carried out full contact tracing and related protocols. Enhanced cleaning protocols were implemented in relevant offices.\"\n",
        "tweet_3 = \"Any tweets only my own views. More Guns,Less Crime (Univ Chicago Press, 3rd ed);10 books, 100+academic articles. PhD Econ, Advisor for Research & Science #USDOJ\"\n",
        "\n",
        "print(\"The similarity score between premise and hypoetheis 1 is:\")\n",
        "print(cosine(infersent.encode([text_prepare(tweet_1)]), infersent.encode([text_prepare(tweet_2)])).tolist()[0])\n",
        "print(\"The similarity score between premise and hypoetheis 2 is:\")\n",
        "print(cosine(infersent.encode([text_prepare(tweet_1)]), infersent.encode([text_prepare(tweet_3)])).tolist()[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The similarity score between premise and hypoetheis 1 is:\n",
            "0.6036133766174316\n",
            "The similarity score between premise and hypoetheis 2 is:\n",
            "0.5492755174636841\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWRo1K9AXdtr"
      },
      "source": [
        "## Look at twitter data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNDrnL63XfZc"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05DvmkGUXh46"
      },
      "source": [
        "df = pd.read_csv(\"tweets.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "RY6fxMQuXmHr",
        "outputId": "ed74d1fc-e2ad-41a4-a6c0-2cb62fa4cb9a"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>coordinates</th>\n",
              "      <th>created_at</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>media</th>\n",
              "      <th>urls</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>id</th>\n",
              "      <th>in_reply_to_screen_name</th>\n",
              "      <th>in_reply_to_status_id</th>\n",
              "      <th>in_reply_to_user_id</th>\n",
              "      <th>lang</th>\n",
              "      <th>place</th>\n",
              "      <th>possibly_sensitive</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>retweet_id</th>\n",
              "      <th>retweet_screen_name</th>\n",
              "      <th>source</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_url</th>\n",
              "      <th>user_created_at</th>\n",
              "      <th>user_screen_name</th>\n",
              "      <th>user_default_profile_image</th>\n",
              "      <th>user_description</th>\n",
              "      <th>user_favourites_count</th>\n",
              "      <th>user_followers_count</th>\n",
              "      <th>user_friends_count</th>\n",
              "      <th>user_listed_count</th>\n",
              "      <th>user_location</th>\n",
              "      <th>user_name</th>\n",
              "      <th>user_screen_name.1</th>\n",
              "      <th>user_statuses_count</th>\n",
              "      <th>user_time_zone</th>\n",
              "      <th>user_urls</th>\n",
              "      <th>user_verified</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Sun Nov 01 03:52:22 +0000 2020</td>\n",
              "      <td>SootinClaimon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://sootinclaimon.com/2020/11/01/the-corona...</td>\n",
              "      <td>0</td>\n",
              "      <td>1322748291646476288</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;a href=\"http://publicize.wp.com/\" rel=\"nofoll...</td>\n",
              "      <td>The coronavirus keeps most London theaters dar...</td>\n",
              "      <td>https://twitter.com/SoilFertilizer/status/1322...</td>\n",
              "      <td>Mon Oct 12 06:58:23 +0000 2009</td>\n",
              "      <td>SoilFertilizer</td>\n",
              "      <td>False</td>\n",
              "      <td>Twitter for Agriculture, Environment, Crops, S...</td>\n",
              "      <td>2</td>\n",
              "      <td>2142</td>\n",
              "      <td>4613</td>\n",
              "      <td>33</td>\n",
              "      <td>Bangkok, Thailand</td>\n",
              "      <td>sootin claimon</td>\n",
              "      <td>SoilFertilizer</td>\n",
              "      <td>414636</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://soclaimon.wordpress.com/</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Sun Nov 01 03:52:52 +0000 2020</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1322748414463979520</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
              "      <td>COVID-19 = Plague</td>\n",
              "      <td>https://twitter.com/TheMJ_OfHustlin/status/132...</td>\n",
              "      <td>Wed Sep 22 03:00:31 +0000 2010</td>\n",
              "      <td>TheMJ_OfHustlin</td>\n",
              "      <td>False</td>\n",
              "      <td>#𝗠𝗿𝗦𝗵𝗼𝗽𝗪𝗶𝘁𝗵𝗠𝗲♦️𝗶𝗺 𝗼𝗻 𝘁𝘄𝗶𝘁𝘁𝗲𝗿 𝗯𝘂𝘁 𝗶𝗺 𝗻𝗼𝘁 𝗮 𝘁𝘄𝗶𝘁...</td>\n",
              "      <td>15194</td>\n",
              "      <td>2041</td>\n",
              "      <td>877</td>\n",
              "      <td>9</td>\n",
              "      <td>Dunder Mifflin</td>\n",
              "      <td>Dr. ShopWithMe™️ 🍭🆓</td>\n",
              "      <td>TheMJ_OfHustlin</td>\n",
              "      <td>89685</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://soundcloud.com/fuck12-1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Sun Nov 01 03:52:42 +0000 2020</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://twitter.com/wdunlap/status/13226760205...</td>\n",
              "      <td>0</td>\n",
              "      <td>1322748372055433216</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
              "      <td>Truly truly sad End the lockdowns re-elect Tru...</td>\n",
              "      <td>https://twitter.com/TCiffo/status/132274837205...</td>\n",
              "      <td>Sat Mar 19 12:44:11 +0000 2016</td>\n",
              "      <td>TCiffo</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>24629</td>\n",
              "      <td>88</td>\n",
              "      <td>239</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Trisha L. Ciffo</td>\n",
              "      <td>TCiffo</td>\n",
              "      <td>30268</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Sun Nov 01 03:52:34 +0000 2020</td>\n",
              "      <td>MurdererInChief</td>\n",
              "      <td>https://twitter.com/LaylaFanucci/status/132274...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1322748339872440320</td>\n",
              "      <td>realDonaldTrump</td>\n",
              "      <td>1.322720e+18</td>\n",
              "      <td>25073877.0</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
              "      <td>@realDonaldTrump A group of Stanford Universit...</td>\n",
              "      <td>https://twitter.com/LaylaFanucci/status/132274...</td>\n",
              "      <td>Wed Nov 16 12:59:30 +0000 2011</td>\n",
              "      <td>LaylaFanucci</td>\n",
              "      <td>False</td>\n",
              "      <td>Layla Fanucci is an International Artist and a...</td>\n",
              "      <td>30547</td>\n",
              "      <td>385</td>\n",
              "      <td>551</td>\n",
              "      <td>8</td>\n",
              "      <td>St Helena, California</td>\n",
              "      <td>Layla Fanucci</td>\n",
              "      <td>LaylaFanucci</td>\n",
              "      <td>95534</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://laylafanucci.com</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Sun Nov 01 03:52:26 +0000 2020</td>\n",
              "      <td>COVID19</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>1322748305898573825</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
              "      <td>A month or so ago around the 26k COV19 cases l...</td>\n",
              "      <td>https://twitter.com/ExcelYourself/status/13227...</td>\n",
              "      <td>Mon Oct 11 14:03:38 +0000 2010</td>\n",
              "      <td>ExcelYourself</td>\n",
              "      <td>False</td>\n",
              "      <td>Author, Excel Expert, CPA. I write the Excel Y...</td>\n",
              "      <td>7045</td>\n",
              "      <td>1010</td>\n",
              "      <td>783</td>\n",
              "      <td>107</td>\n",
              "      <td>Western Australia</td>\n",
              "      <td>Neale Blackwood</td>\n",
              "      <td>ExcelYourself</td>\n",
              "      <td>34576</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://a4accounting.com.au</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  coordinates  ... user_verified\n",
              "0         NaN  ...         False\n",
              "1         NaN  ...         False\n",
              "2         NaN  ...         False\n",
              "3         NaN  ...         False\n",
              "4         NaN  ...         False\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjZVe6kdXuYr"
      },
      "source": [
        "tweets = df.text.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uj4s_VuwSJBx"
      },
      "source": [
        "processed_tweets = list(map(text_prepare, tweets))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWVM8DHNTWLi"
      },
      "source": [
        "assert len(tweets) == len(df) == len(processed_tweets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRQP3p9USP-i",
        "outputId": "73366c0c-6635-4021-f8ae-39e2c8e66ce6"
      },
      "source": [
        "processed_tweets[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The coronavirus keeps most London theaters dark, while performers stock grocery shelves #SootinClaimon.Com https://t.co/QIClzfE6Zw',\n",
              " 'COVID-19 = Plague',\n",
              " 'Truly truly sad End the lockdowns re-elect Trump🇺🇸the choice is clear! https://t.co/uvz04Yg7A5',\n",
              " '@realDonaldTrump A group of Stanford University economists estimates that there have been at least 30,000 coronavirus infections and 700 deaths as a result of 18 campaign rallies President Trump held between June and September. #MurdererInChief https://t.co/JBnmASpmJH',\n",
              " 'A month or so ago around the 26k COV19 cases level Australia + Austria were very close on both total cases + daily numbers. Australia has just had a zero day with 27k total cases + Austria has 104k total cases and 5k per day. Things can change rapidly with #COVID19']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV5dO6xIZQ7s",
        "outputId": "cab1e8c1-0057-44ea-ba2f-f59157a20f7e"
      },
      "source": [
        "infersent.is_cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOd8tZwKS8nv"
      },
      "source": [
        "all_tweets_emb = infersent.encode(processed_tweets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRxmtKIGTBRV",
        "outputId": "08c8bd16-752c-4a14-abee-37e63d49fb17"
      },
      "source": [
        "all_tweets_emb.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1177, 4096)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8LC_btcSQsL",
        "outputId": "e7ed1e95-28bc-4ae8-9fd4-e7f13d310410"
      },
      "source": [
        "all_scores = np.zeros((len(tweets), len(tweets)))\n",
        "for i in range(len(processed_tweets)):\n",
        "  candidate_emb = infersent.encode([processed_tweets[i]])\n",
        "  all_scores[i] = cosine(np.repeat(candidate_emb, len(processed_tweets), axis=0), all_tweets_emb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in log\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J78jhzZYTMua",
        "outputId": "c98341ee-a2fe-45fd-bed7-dca7b526ff51"
      },
      "source": [
        "all_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.99999952,         nan, -0.12126875, ..., -0.83017385,\n",
              "         0.17898256,  0.40660882],\n",
              "       [        nan,  1.00000024, -2.23927402, ..., -0.15725315,\n",
              "        -0.87136412,         nan],\n",
              "       [-0.12126887, -2.23927402,  1.        , ..., -0.16158223,\n",
              "        -0.29706645,  0.08433688],\n",
              "       ...,\n",
              "       [-0.83017385, -0.15725315, -0.16158223, ...,  1.00000012,\n",
              "        -0.1731993 , -0.10724354],\n",
              "       [ 0.17898256, -0.871364  , -0.29706645, ..., -0.1731993 ,\n",
              "         0.99999994,  0.19178766],\n",
              "       [ 0.40660894,         nan,  0.08433682, ..., -0.10724354,\n",
              "         0.1917876 ,  1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ko7_Z-P1TQ4n",
        "outputId": "87b723e0-55de-4d62-dca7-e27d9eb8d79e"
      },
      "source": [
        "cosine(infersent.encode([processed_tweets[0]]), infersent.encode([processed_tweets[1]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in log\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([nan], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcRCznMoYpRH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}